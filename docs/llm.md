# LLM 面试题目和知识点

## 知识点

1. **基础概念**:
    - 什么是大型语言模型（LLM）？
    - LLM 的主要应用有哪些？

2. **技术细节**:
    - 语言模型的训练方法有哪些？
    - Transformer 架构的基本原理是什么？

    例如，Transformer 中的 Scaled Dot-Product Attention 计算公式如下：

    $\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$

3. **实战问题**:
    - 如何处理模型的过拟合和欠拟合问题？
    - 如何提升模型的推理速度？

## 面试题目

1. 请解释一下 Attention 机制的原理。
2. 如何评估一个语言模型的性能？
3. Transformer 中的 Multi-Head Attention 是如何工作的？
4. 什么是 BERT 模型，它与传统的语言模型有何不同？
5. 如何在实际应用中选择适合的预训练模型？
